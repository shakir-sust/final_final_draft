---
title: "Data Science Applied to Ag - Final Project - ML"
format:
  html:
    embed-resources: true
    toc: true
    theme: cerulean
author: FIRST LAST
---

# A. Introduction  
This file contains the **instructions** for the final project.  

To get you setup, you will need to:  

  - Student #1: create a repository on your GitHub account. You can call this repository "2025dsa_finalproject_groupX", **where X is the number of your group**. Make it public, add a README, add a .gitignore for R.  
  - Student #1: follow the steps we did in class to start a new RStudio project with version control.  
  - Student #1: in your computer, create the sub-folders code, data, output, and move your data set into the `data` folder. Also, student 1 moves this current script into the `code` folder. Do a git stage, commit, push.  
  - Student #1: on GitHub, go the repository settings and invite your partner to be a collaborator in the repository. That will give them push permission.  
  - Now, both students should clone this repository on their computers like we did in class. Make sure this step works well and that you can pull and push from GitHub.  
  - Student 2, after cloning, does a git pull to get all these updates on their computer.  
  - Student 1 and 2 work together to update the README file. README files should explain what the repository is about, the goals of that project, who is working in it, and any other important details you may find.  

# B. Defining the problem  

You are being provided with a **corn variety trial** data set.  
This data contains over **164,000 rows** spanning **10 years** (2014-2023), **45 sites** across the USA, for a total of **270** site-years, where over **5,000** corn hybrids were evaluated.  

You are being provided with the following **training data** for years 2014-2023:   

  - Trait information (including site, year, hybrid, yield, and grain moisture) [the yield that we see in this "trait information" is for whatever moisture it is being reported right next to it. We will need to transform this to 15.5% moisture, which is the default that we report the corn grain yield] 
  - Meta information (including site, year, previous crop, planting date, harvest date, longitude, and latitude)  
  - Soil information (including site, year, soil pH, soil organic matter, soil P, soil K)  

You are also being provided with the following **testing data** for year 2024:  
  - Submission information (site, year, hybrid, **no yield**)  
  - Meta information (same as training)  
  - Soil information (same as training)  

> You are tasked in training machine learning models using the training data to predict yield on the test data.  

One difference from class is that **you are not provided with the test data yield (predicted variable)**, only the predictor variables.  
Therefore, using the training data wisely to create predictive models will be important.  


# C. Open-source data  
Notice you were provided with the **longitude and latitude** of most of the site-years.  
You are encouraged to use this information to pull any external open-source data sets like **weather** [using the longitude and latitude data], or anything else you may find useful.  

This will be up to each team.
Part of creating a great model is incorporating different pieces of information.  

# D. Feature engineering  
Your goal is to create good predictor variables in your data set for modelling.  

It is up to each team how you will perform feature engineering.  

For ex. in class we summarized weather on a monthly basis, but perhaps this is not the best approach. [e.g., maybe we can use weather data summarized by the whole growing season, every two weeks, crop growth stages etc.]

[Note from feature engineering script:

There are **two components** that we can consider when feature engineering weather data:  

1. Summarizing time **window size**  
  - Weekly  
  - Monthly  
  - Every 2 months  
  - (Entire) Growing season  
  - Based on crop growth stages [if we have planting and harvest date]
  - Other?  [growing degree days based on temperature data]
  
2. Summarizing **function**  
  - Mean  
  - Median  
  - Minimum  
  - Maximum  
  - Standard deviation  

In the next section, let's use the following:  
  - Summarizing time window size: **monthly**  
  - Summarizing function: **mean** or **sum**  

]

# E. Modeling strategies  
You are asked to fully train two different machine learning models:  
  - XGboost (everyone)  [because XGboost is one of the best preforming models when we have tabular data]
  - **One more model of your choice**.  

You can find a list of all tidymodels supported models here:  
https://www.tidymodels.org/find/parsnip/  

# F. Training strategies  
For both XGboost and the 2nd model of your choice, the entire training process is up to you.  
That means you decide things like  
  - Data split proportions  
  - Pre-processing steps  
  - Hyper-parameters to fine tune  
  - Search strategy [e.g., fixed grid, iterative search]
  - Resampling strategy  [e.g., v-fold cross validation]
  - Which metric to use to select best model [e.g., R2, RMSE]  
  - Which type of model selection to use (e.g., best model, best within 1 sd, best within a given percent loss etc.)  
  
# G. Communicating your results  
You will be required to create a **shiny app** to communicate your results.  
Select one of your final models (XGboost or the other one), and display its results in the app.
While the shiny app design is up to you, it should contain:  
  - At least one EDA on yield based on the training data  [e.g., may be it's a geom_density, or maybe it's a map of USA with points, etc.]
  - EDA on at least 1 predictor variable of each group (soil, weather)  [soil data has 5 predictor variables, we need to show EDA on at least 1 predictor variable; for weather data, we need to show EDA plot for at least 1 weather predictor variables.]
  - At least one interactive component [may be one can zoom in/ zoom out, maybe one can select what variable they want to see in the Shiny app plot]  
  - A plot showing the most important variables in your model  [variable importance plot for the best model]
  - A plot for predicted vs observed with R2 and RMSE on you testing set (not the one I provide)  

# H. Troubleshooting  
You will for sure run into code issues.  
This is common and expected, and part of the learning process.  

While this is an individual project, I do encourage all students to help each other, especially as you will likely run into similar problems.  

For that to work, we will be using **GitHub** to ask and answer questions.  

ALL QUESTIONS should be asked in our course GitHub page (https://github.com/leombastos/2025_ppa) under "Issues". **Please do not use email for asking questions**.

Make sure to **"Watch"** the repository so you get notified when someone posts on Issues.  

> I anticipate all of you will have multiple questions. The goal with using GitHub is that you can help each other. You will be graded for participation both in asking questions on GitHub and also helping others with their questions.  

With that, when you have issues running code, here are a few resources you can use, in chronological order:  

- **Yourself**: Read the error message, see if you can interpret it and understand what is going on. A message like "Error: object yield could not be found" is self-explanatory.    
- **Google**: Sometimes just copying an error message and pasting on Google can help you find posts with the answer.  
- **Peers**: ask your classmates using GitHub.  
- **Me**: after you have gone through all the sources above without success, I will certainly be glad to assist you. I want to be the last resource you use because that's how it will be after our class is finished: I will be available to assist you in anything R-related in your career, but you will also need to attempt solving them before you reach out.  

# I. Turning it in  
You are required to turn in the following:  
  - The github repository URL containing ALL the code for the ML training process  
  - The completed `testing_submission` file with your predictions for the test data that I shared with you  
  - The URL for the shiny app  
  
Submit the github URL, the `testing_submisison` csv, and the shiny app URL on eLC by **April 30th** 11:59 pm.  
  
# J. Grading  
You will be graded based on:  
  - following general workflows we did in class for all steps (open-source data retrieval and processing, feature engineering, ML model training, etc.)  [explain and mention what each code chunk is about]
  - following reproducible standards like sensible folder and file naming, script organization, script comments, etc.  
  - collaborating with your partner in GitHub  
  - submitting all three pieces of information (2 URLs [1 for GitHub repo; another for Shiny app], one file [with predictions] )  
  - submitting on time  
  - having a shiny dashboard with the minimum requirements listed above  

# K. Team work in GitHub  
Whether you are working with your future-self or as duos, make sure to stage, commit, and push after finishing each of the sub-sections above. When committing, write commit messages that are short and descriptive (e.g., finished wrangling).  

If you are working in duos, make sure to split the workload. I will check your collaborative work through the commit history, and if one student has contributed significantly more than the other, than that will impact grades.  

**Tip 1**: to avoid merge conflicts, make sure to **pull** first, and then start working locally. That will ensure that any changes made by your partner will be "downloaded" before you make changes to the files locally.  

**Tip 2**: make use of the Issues on this repository to set up to-do lists and assign tasks to different people. You can also use each issue/task to discuss how things should be run and get to an agreement.  

# L. Extra  
Once each team submits their predictions on my test set, I will compare their predictions with the observed values (that you don't have).  

The team that gets the highest **R2** will receive an award and bragging rights.  

