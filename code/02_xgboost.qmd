---
title: "Data Science Applied to Ag - Final Project - ML"
format:
  html:
    embed-resources: true
    toc: true
    theme: cerulean
author: Md Shakir Moazzem, Umar Munir
---

# Introduction

This script contains ML Workflow with XGBoost

## Loading libraries

The following code chunk will load necessary packages.

```{r}
#| message: false
#| warning: false

#install.packages("tidymodels")   # Core framework for modeling (includes recipes, workflows, parsnip, etc.)
#install.packages("finetune")     # Additional tuning strategies (e.g., racing, ANOVA-based tuning)
#install.packages("vip")          # For plotting variable importance from fitted models
#install.packages("xgboost")      # XGBoost implementation in R
#install.packages("ranger")       # Fast implementation of Random Forests
#install.packages("tidyverse")    # Data wrangling and visualization
#install.packages("doParallel")   # For parallel computing (useful during resampling/tuning)
#install.packages("caret")  
#install.packages("xgboost") #new pacakage
#install.packages("caret")

library(tidymodels)   # Core framework for modeling (includes recipes, workflows, parsnip, etc.)
library(finetune)     # Additional tuning strategies (e.g., racing, ANOVA-based tuning)
library(vip)          # For plotting variable importance from fitted models
library(xgboost)      # XGBoost implementation in R
library(ranger)       # Fast implementation of Random Forests
library(tidyverse)    # Data wrangling and visualization
library(doParallel)   # For parallel computing (useful during resampling/tuning)
library(caret)       # Other great library for Machine Learning 
```

## Loading the data set

The following code chunk will load the "weather_monthsum.csv" data set.

```{r weather}

rm(weather)

weather <- read_csv("../data/weather_monthsum.csv") %>%
  rename(yield = adjusted_yield)

weather

```

# EDA on predictors   

The following code chunk will print ridge plots to visualize the distribution of the following soil-related predictors: "mean_soil.ph_Sep", "mean_soil.om.pct_Sep", "mean_soil.k.ppm_Sep", and "mean_soil.p.ppm_Sep".  

```{r message=F, warning=F}

#install.packages("tidyverse")
#install.packages("ggridges")
#install.packages("viridis")
#install.packages("purrr")

library(tidyverse)
library(ggridges)
library(viridis)
library(purrr)

# Specifying the four variables 
selected_vars <- c(
  "mean_soil.ph_Sep",
  "mean_soil.om.pct_Sep",
  "mean_soil.k.ppm_Sep",
  "mean_soil.p.ppm_Sep"
)

# Walking over them, computing a per‐variable scale, and printing one ridge plot per var
walk(
  selected_vars,
  function(var) {
    # estimate density to find its max height
    dens      <- density(weather[[var]], na.rm = TRUE)
    scale_val <- 1 / max(dens$y, na.rm = TRUE)

    soil_eda_sep <- ggplot(weather, aes(x = .data[[var]], y = var, fill = stat(x))) +
      geom_density_ridges_gradient(
        scale          = scale_val,
        rel_min_height = 0.01
      ) +
      scale_fill_viridis_c(option = "C") +
      labs(
        title = paste("Distribution of", var),
        x     = "Value",
        y     = NULL
      ) +
      theme_ridges() +
      theme(
        legend.position = "none",
        axis.text.y     = element_blank()
      )

    print(soil_eda_sep)
  }
)


```
The following code chunk will print ridge plots to visualize the distribution of the following weather-related predictors: "mean_srad.wm2_Sep", "mean_tmax.c_Sep", "mean_tmin.c_Sep", "mean_vp.pa_Sep", "sum_prcp.mm_Sep"


```{r}

# Specifying exactly the five Sep weather predictors 
selected_vars <- c(
  "mean_srad.wm2_Sep",
  "mean_tmax.c_Sep",
  "mean_tmin.c_Sep",
  "mean_vp.pa_Sep",
  "sum_prcp.mm_Sep"
)

# Iterating with walk(), computing a per‐variable scale and printing one ridge plot per var
walk(
  selected_vars,
  function(var) {
    # compute density to get max height for scaling
    dens      <- density(weather[[var]], na.rm = TRUE)
    scale_val <- 1 / max(dens$y, na.rm = TRUE)

    weather_eda_sep <- ggplot(weather, aes(x = .data[[var]], y = var, fill = stat(x))) +
      geom_density_ridges_gradient(
        scale          = scale_val,
        rel_min_height = 0.01
      ) +
      scale_fill_viridis_c(option = "C") +
      labs(
        title = paste("Distribution of", var),
        x     = "Value",
        y     = NULL
      ) +
      theme_ridges() +
      theme(
        legend.position = "none",
        axis.text.y     = element_blank()
      )

    print(weather_eda_sep)
  }
)

```

# ML workflow

## 1. Pre-processing

### a. Data split

The following code chunks will conduct data split (70% training / 30% testing).

```{r weather_split}

set.seed(931735) # Setting seed to get reproducible results 

weather_split <- initial_split(
  weather, 
  prop = .7, # proption of split same as previous codes
  strata = yield  # Stratify by target variable
  )

weather_split

```

The following code chunk will conduct setting train set.

```{r weather_train}

weather_train <- training(weather_split)  # 70% of data

weather_train #This is the traing data frame

```

The following code chunk will conduct setting test split.


```{r weather_test}

weather_test <- testing(weather_split)    # 30% of data

weather_test

```

### b. Distribution of target variable "yield"

The following code chunk will create a density plot to compare target variable "yield" in the training and test set.

```{r distribution}

EDA_yield <- ggplot() +
  geom_density(data = weather_train, 
               aes(x = yield),
               color = "red") +
  geom_density(data = weather_test, 
               aes(x = yield),
               color = "blue") 
  

EDA_yield

```

### c. Data processing with recipe

The following code chunk will conduct data processing with recipe.

```{r weather_recipe}

# Create recipe for data preprocessing
weather_recipe <- recipe(yield ~ ., data = weather_train) %>% 
  # Remove identifier columns and months not in growing season
  step_rm(
    year,       # Remove year identifier
    site,       # Remove site identifier
    hybrid,     # Remove site identifier
    matches("Jan|Feb|Mar|Nov|Dec")  # Remove non-growing season months
  ) 


weather_recipe

```

The following code chunk will prep the recipe to estimate any required statistics.

```{r weather_prep}
# Prep the recipe to estimate any required statistics
weather_prep <- weather_recipe %>% 
  prep()

# Examine preprocessing steps
weather_prep
```

## 2. Training

### a. Model specification

The following code chunk will fine tune the "trees", "tree_depth", "min_n", and "learn_rate" XgBoost hyperparameters.

```{r xgb_spec}

xgb_spec <- boost_tree(
  trees = tune(),
  tree_depth = tune(),  # Maximum depth of each tree
  #min_n = tune(),  # Minimum samples required to split a node
  #learn_rate = tune()
  ) %>% #Specifying XgBoost as our model type, asking to tune the hyperparameters
  set_engine("xgboost") %>% #specify engine 
  set_mode("regression")  # Set to mode
      
xgb_spec

```

### b. Cross-validation setup

The following code chunk will conduct 5-fold cross-validation to evaluate model performance during tuning.

```{r}

set.seed(235) #34549

resampling_foldcv <- vfold_cv(weather_train, 
                              v = 3)

resampling_foldcv

resampling_foldcv$splits[[1]]

```

### c. Hyperparameter grid with Latin Hypercube Sampling

The following code chunk will use Latin hypercube sampling to generate a diverse grid of hyperparameter combinations.

```{r }

xgb_grid <- grid_latin_hypercube(
  trees(),
  tree_depth(),
  #min_n(),
  #learn_rate(),
  size = 5
)

xgb_grid

```

The following code chunk will plot the hyperparameter combinations.

Note: The plot will not generate if "min_n" and "learn_rate" were not fine tuned.

```{r}
#ggplot(data = xgb_grid,
       #aes(x = tree_depth, 
           #y = min_n)) +
  #geom_point(aes(color = factor(learn_rate), #coloring the bubbles based on learn_rate
                 #size = trees), #size of the bubbles are based on the tress
             #alpha = .5,
             #show.legend = FALSE)
```

## 3. Model Tuning

The following code chunk will conduct model tuning.

Note: It took 1 hr 40 min to run the code chunk below.

```{r xgb_grid_result}

#install.packages("doParallel")
#install.packages("parallel")

library(doParallel)
library(parallel)

set.seed(76544)

#parallel processing
#registerDoParallel(cores = parallel::detectCores()-1) #starts parallel processing

xgb_res <- tune_race_anova(object = xgb_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                      grid = xgb_grid,
                      control = control_race(save_pred = TRUE))

#stopImplicitCluster() #ends parallel processing

beepr::beep()

xgb_res$.metrics[[2]]

```

## 4. Select Best Models

We select the best models using three strategies (lowest RMSE, highest R2, within 1 SE, within 2% loss).

The following code chunk will select best model based on lowest RMSE.

```{r}

# Based on lowest RMSE
best_rmse <- xgb_res %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse")

best_rmse

```

The following code chunk will select best model based on lowest RMSE within 1% loss

```{r}
# Based on lowest RMSE within 1% loss
best_rmse_pct_loss <- xgb_res %>% 
  select_by_pct_loss("min_n",
                     metric = "rmse",
                     limit = 1
                     )%>% 
  mutate(source = "best_rmse_pct_loss")

best_rmse_pct_loss
```

The following code chunk will select best model based on lowest RMSE within 1 SE.

```{r}
# Based on lowest RMSE within 1 se
best_rmse_one_std_err <- xgb_res %>% 
  select_by_one_std_err(metric = "rmse",
                        eval_time = 100,
                        trees
                        )%>% 
  mutate(source = "best_rmse_one_std_err")

best_rmse_one_std_err
```

The following code chunk will select best model based on greatest R2.

```{r}
# Based on greatest R2
best_r2 <- xgb_res %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2")

best_r2
```

The following code chunk will select best model based on greatest R2 within 1% loss.

```{r}
# Based on greatest R2 within 1% loss
best_r2_pct_loss <- xgb_res %>% 
  select_by_pct_loss("min_n",
                     metric = "rsq",
                     limit = 1
                     ) %>% 
  mutate(source = "best_r2_pct_loss")

best_r2_pct_loss
```

The following code chunk will select best model based on greatest R2 within 1 SE

```{r}
# Based on greatest R2 within 1 se
best_r2_one_std_error <- xgb_res %>% 
  select_by_one_std_err(metric = "rsq",
                        eval_time = 100,
                        trees
                        ) %>%
  mutate(source = "best_r2_one_std_error")

best_r2_one_std_error
```

## Compare and Finalize Model

The following code chunk will compare all models

```{r comparing values}
best_rmse %>% 
  bind_rows(best_rmse_pct_loss, 
            best_rmse_one_std_err, 
            best_r2, 
            best_r2_pct_loss, 
            best_r2_one_std_error)
```

## 5. Final Specification

The following code chunk will conduct final specification.

```{r final_spec_fit}

final_spec <- boost_tree(
  trees = best_r2$trees,           # Number of boosting rounds (trees)
  tree_depth = best_r2$tree_depth, # Maximum depth of each tree
  #min_n = best_r2$min_n,           # Minimum number of samples to split a node
  #learn_rate = best_r2$learn_rate  # Learning rate (step size shrinkage)
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

final_spec

```

## 6. Final Fit and Predictions

## Validation

The following code chunk will conduct the final fit and collect predictions on the final fit.

```{r final_fit}

set.seed(10)

#rm(final_fit)

final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()

```

## 7. Evaluate on *Test Set*

The following code chunk will evaluate fit metrics on the test set.

```{r final_fit_metrics}

final_fit %>%
  collect_metrics()

```

## 8. Evaluate on Training Set

The following code chunk will evaluate fit metrics on the training set.

```{r}
final_spec %>%
  fit(yield ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(yield, .pred) %>%
  bind_rows(
    
    
# R2
final_spec %>%
  fit(yield ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rsq(yield, .pred))
```

## 9. Predicted vs Observed Plot

The following code chunk will create a Predicted vs Observed Plot.

```{r}

final_fit %>%
  collect_predictions() %>%
  ggplot(aes(x = yield,
             y = .pred)) +
  geom_point() +
  geom_abline() +
  geom_smooth(method = "lm") +
  scale_x_continuous() +
  scale_y_continuous() 

```

*The following code chunk will show RMSE and R2 in the Predicted vs Observed Plot.*

```{r pred_vs_obs_with_metrics, message=FALSE, warning=FALSE}

library(dplyr)
library(ggplot2)
library(yardstick)

# collecting predictions & computing metrics
preds <- final_fit %>% 
  collect_predictions()

metrics_tbl <- preds %>%
  metrics(truth = yield, estimate = .pred) %>%
  filter(.metric %in% c("rmse","rsq")) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)

rmse_val <- metrics_tbl$rmse
r2_val   <- metrics_tbl$rsq

# calculating dynamic offsets
y_rng     <- range(preds$.pred, na.rm = TRUE)
x_rng     <- range(preds$yield, na.rm = TRUE)
y_offset  <- diff(y_rng) * 0.04  # move 10% of y-range upward
x_offset  <- diff(x_rng) * 0.02  # (optional) small right‐shift

# plotting the predicted vs observed plot with R² & RMSE
pred_vs_obs_plot <-
  ggplot(preds, aes(x = yield, y = .pred)) +
  geom_point(alpha = 0.6) +
  geom_abline(linetype = "solid") +
  geom_smooth(method = "lm", se = FALSE) +
  annotate(
    "text",
    x     = x_rng[1] + x_offset,
    y     = y_rng[2] + y_offset,
    label = sprintf("R² = %.3f\nRMSE = %.2f", r2_val, rmse_val),
    hjust = 0,
    vjust = 0
  ) +
  scale_x_continuous(name = "Observed Yield") +
  scale_y_continuous(name = "Predicted Yield") +
  ggtitle("Predicted vs Observed Yield with R² & RMSE")


pred_vs_obs_plot


```



## 10. Variable Importance

The following code chunk will create a Variable Importance plot.

```{r final_spec}

var_imp_plot <- final_spec %>%
  fit(yield ~ .,
         data = bake(weather_prep, weather_train)) %>% #There little change in variable improtance if you use full dataset
    vi() %>%
  mutate(
    Variable = fct_reorder(Variable, 
                           Importance)
  ) %>%
  ggplot(aes(x = Importance, 
             y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

var_imp_plot

```


# Obtaining "yield" prediction on the "testing_submission.csv" data set


```{r}




```

